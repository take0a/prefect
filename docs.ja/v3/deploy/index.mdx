---
title: Deploy overview
sidebarTitle: Overview
description: デプロイメントを使用してフロー実行をリモートでトリガーする方法を学習します。
---

デプロイメントを使用すると、[スケジュール](/v3/automate/add-schedules/)に基づいてフローを実行したり、[イベント](/v3/automate/events/automations-triggers/)に基づいて実行をトリガーしたりできます。

デプロイメントは、フローをサーバー側で表現したものです。
ワークフローをいつ、どこで、どのように実行するかなど、リモートオーケストレーションに不可欠なメタデータを保存します。

フロー実行を手動でトリガーおよび管理するだけでなく、フローをデプロイすると、次の操作を実行できる API と UI が公開されます。

- 新しい実行のトリガー、[アクティブな実行のキャンセル](/v3/develop/write-flows/#cancel-a-flow-run)、スケジュール済みの実行の一時停止、パラメータのカスタマイズなど
- [スケジュール](/v3/automate/add-schedules) と [自動化ルール](/v3/automate/events/automations-triggers) をリモートで設定
- [ワークプール](/v3/deploy/infrastructure-concepts/work-pools) を使用してインフラストラクチャを動的にプロビジョニング - オプションで、他のユーザー向けのテンプレート化されたガードレールを使用

## デプロイメントを作成する

### `serve` を使ってデプロイメントを作成する

これがデプロイメントを始める最も簡単な方法です:

```python
from prefect import flow


@flow
def my_flow():
    print("Hello, Prefect!")


if __name__ == "__main__":
    my_flow.serve(name="my-first-deployment", cron="* * * * *")
```

`serve` メソッドはフローからデプロイメントを作成し、すぐにスケジュールされた実行のリッスンを開始します。
`.serve` に `cron="* * * * *"` を指定すると、フローにスケジュールが関連付けられ、毎日毎分実行されます。

より詳細な構成が必要な場合は、ワークプールを使用するデプロイメントを作成できます。
ワークプールベースのデプロイメントを作成する理由としては、次のようなものが挙げられます。

- 動的にプロビジョニングされたインフラストラクチャ上でフローを実行したい場合
- フロー実行ごとに実行環境をより細かく制御する必要がある場合
- デプロイメント全体で使用できるインフラストラクチャテンプレートを作成する場合

ワークプールは、組織全体のインフラストラクチャ構成を管理できるため、データプラットフォームチームに人気があります。

### ワークプールベースのデプロイメントを作成する

Prefect では、ワークプールベースのデプロイメントを作成するために、Python スクリプトと YAML ファイルの 2 つのオプションが用意されています。

### `deploy` でデプロイメントを作成する

Python スクリプトでデプロイメントを定義するには、`flow.deploy` メソッドを使用します。

以下は、ワークプールを使用し、コードを Docker イメージにベイクするデプロイメントの例です。

```python
from prefect import flow


@flow
def my_flow():
    print("Hello, Prefect!")

if __name__ == "__main__":
    my_flow.deploy(
        name="my-second-deployment",
        work_pool_name="my-work-pool",
        image="my-image",
        push=False,
        cron="* * * * *",
    )
```

`deploy` メソッドの詳細については、[Python を使用したフローのデプロイ](/v3/deploy/infrastructure-concepts/deploy-via-python) を参照してください。

### YAML ファイルでデプロイメントを作成する

YAML ファイルを使って宣言的なアプローチでデプロイメントを定義したい場合は、[`prefect.yaml` ファイル](/v3/deploy/infrastructure-concepts/prefect-yaml) を使用してください。

Prefect は、`prefect.yaml` ファイルの作成手順を案内する対話型 CLI を提供しています。

```bash
prefect deploy
```

結果として、デプロイメント作成用の `prefect.yaml` ファイルが作成されます。
このファイルには、Docker イメージのビルド、Docker レジストリへのコードのプッシュ、実行時のコードのプルを行うための `build`、`push`、`pull` ステップが含まれています。
YAML ファイルを使用したデプロイメントの作成の詳細については、[YAML を使用したデプロイメントの定義](/v3/deploy/infrastructure-concepts/prefect-yaml) を参照してください。

Prefect は、YAML ベースのデプロイメントを自動的に作成するための [CI/CD オプション](/v3/deploy/infrastructure-concepts/deploy-ci-cd) も提供しています。

### Terraform でデプロイメントを作成する

import { TF } from "/snippets/resource-management/terraform.mdx"
import { deployments } from "/snippets/resource-management/vars.mdx"

<TF name="deployments" href={deployments.tf} />

### APIを使用してデプロイメントを作成する

import { API } from "/snippets/resource-management/api.mdx"

<API name="deployments" href={deployments.api} />

### ワークプール

[ワークプール](/v3/deploy/infrastructure-concepts/work-pools/)を使用すると、異なるタイプのインフラストラクチャを切り替えたり、デプロイメント用のテンプレートを作成したりできます。
データプラットフォームチームにとって、ワークプールはデータプロフェッショナルのチーム間でインフラストラクチャ構成を管理するのに特に便利です。

一般的な作業プールの種類には、[Docker](/v3/deploy/infrastructure-examples/docker)、[Kubernetes](/v3/deploy/infrastructure-examples/kubernetes)、および [AWS ECS](/integrations/prefect-aws/ecs_guide#ecs-worker-guide)、[Azure ACI](/integrations/prefect-azure/aci_worker)、[GCP Vertex AI](/integrations/prefect-gcp/index#run-flows-on-google-cloud-run-or-vertex-ai)、[GCP Google Cloud Run](/integrations/prefect-gcp/gcp-worker-guide) などのサーバーレス オプションがあります。

### ワークプールベースのデプロイメント要件

Python SDK で作成され、ワー​​クプールを使用するデプロイメントには、`name` が必要です。
この値がデプロイメント名になります。
`work_pool_name` も必須です。

フローコードの場所は、いくつかの方法で指定できます。

1. Docker イメージにベイクする（Docker イメージを使用するワークプールの場合）。
上記の例に示すように、Prefect は Python SDK で作成されたデプロイメントのデフォルトの方法としてこれをサポートしています。
この方法では、`deploy` メソッドで `image` 引数を指定する必要があります。
2. フローで `from_source` を呼び出し、次のいずれかを指定します。
    1. Git ベースのクラウドプロバイダーの場所（例：GitHub）
    2. クラウドプロバイダーのストレージの場所（例：AWS S3）
    3. ローカルパス（プロセスワークプールのオプション）

フローコードのストレージの詳細については、[ストレージからのコードの取得に関するドキュメント](/v3/deploy/infrastructure-concepts/store-flow-code)を参照してください。

## デプロイメントを実行する

デプロイメントは、手動で実行したり、[スケジュール](/v3/automate/add-schedules#schedule-flow-runs)、または[イベントに応じて](/v3/automate/events/automations-triggers)実行するように設定できます。

デプロイメントはワークプールからインフラストラクチャ構成を継承し、デプロイメント作成時または実行時にオーバーライドできます。

### ワーカーを必要とするワークプール

Docker や Kubernetes などのハイブリッドワークプールタイプでデプロイメントを実行するには、[ワーカー](/v3/deploy/infrastructure-concepts/workers/) を起動する必要があります。

[Prefect ワーカー](/v3/deploy/infrastructure-concepts/workers) は、一致するワークプール内でスケジュールされたフロー実行をチェックするクライアント側プロセスです。
スケジュールされた実行が見つかると、ワーカーは指定されたインフラストラクチャ上でフロー実行を開始し、完了するまでフロー実行を監視します。

### ワーカーを必要としないワークプール

Prefect Cloud は、ワーカーなしでクラウドプロバイダーのサーバーレスインフラストラクチャ上でフローを実行し、迅速にセットアップできる [push ワークプール](/v3/deploy/infrastructure-examples/serverless#automatically-create-a-new-push-work-pool-and-provision-infrastructure) を提供しています。

Prefect Cloud は、[Prefect マネージドワークプール](/v3/deploy/infrastructure-examples/managed) を通じて Prefect のインフラストラクチャ上でワークフローを実行するオプションも提供しています。

これらのワークプールタイプでは、フローを実行するためにワーカーは必要ありません。
ただし、Prefect との情報共有が多少必要になるため、組織のセキュリティ体制によっては困難となる可能性があります。

## 静的インフラストラクチャ vs. 動的インフラストラクチャ

フローは、長期にわたって利用可能な静的インフラストラクチャ、または水平方向にスケール可能な動的インフラストラクチャにデプロイできます。
最適な選択はユースケースによって異なります。

### 静的インフラストラクチャ

複数のフローを定期的に実行する場合、`Flow` オブジェクトの [`serve` メソッド](/v3/deploy/run-flows-in-local-processes#serve-a-flow) または [`serve` ユーティリティ](/v3/develop/write-flows/#serving-multiple-flows-at-once) は、複数のフローを同時に管理するのに最適なオプションです。

フローを作成し、デプロイ設定を決定したら、この長時間実行プロセスを任意の場所で実行します。
プロセスは Prefect API と通信を続け、作業を監視し、各実行を個別のサブプロセスに送信します。
実行はサブプロセスに送信されるため、外部インフラストラクチャの設定は事前に設定し、このプロセスと関連付けておく必要があります。

このアプローチの利点は次のとおりです:

- ユーザーはインフラストラクチャを完全に制御でき、「serve」Python プロセスが実行できる場所であればどこでも適切なデプロイ環境となります。
- 理解が容易です。
- デプロイメントの作成には最小限の決定が必要です。
- 反復処理の速度が速いです。

### 動的インフラストラクチャ

以下のいずれかの条件に該当する場合は、ワークプールを使用して動的にプロビジョニングされたインフラストラクチャ上でフローを実行することを検討してください。

- 長時間実行されるプロセスのために、高価なインフラストラクチャを必要とするフロー。
- 実行ごとに異なるインフラストラクチャを必要とするフロー。
- 大量のデプロイメント。
- デプロイメントの作成者または実行者が、インフラストラクチャを管理するチームのメンバーではないという社内組織構造。

[ワークプール](/v3/deploy/infrastructure-concepts/work-pools/)を使用すると、Prefect はフローが実行されるインフラストラクチャをより詳細に制御できます。
[サーバーレス ワークプール](/v3/deploy/infrastructure-examples/serverless/) のオプションを使用すると、ワークフローが実行されていないときにスケールをゼロにすることができます。
Prefect Cloud プッシュワークプールオプションを使用すると、Prefect では [単一の CLI コマンドでクラウドインフラストラクチャをプロビジョニング](/v3/deploy/infrastructure-examples/serverless/#automatically-create-a-new-push-work-pool-and-provision-infrastructure) する機能も提供されます。

ワークプールを使用する場合：

- Prefect UI 内でインフラストラクチャ構成を設定および監視できます。
- インフラストラクチャは一時的なものであり、動的にプロビジョニングされます。
- Prefect はインフラストラクチャをより意識しており、デフォルトでインフラストラクチャからより多くのイベントデータを収集します。
- 高度に分離されたセットアップが可能です。

<Note>
**1つのアプローチに固執する必要はありません**

各フローのニーズに合わせて、複数のアプローチを組み合わせることができます。また、特定のフローのニーズの変化に合わせて、デプロイ方法を変更することも可能です。
例えば、高負荷な機械学習パイプラインにはワーカーを使用し、小規模で頻度の高いファイル処理パイプラインにはサーブメカニズムを使用するといった具合です。
</Note>

## デプロイメントスキーマ

{/* pmd-metadata: notest */}
```python
class Deployment:
    """
    Structure of the schema defining a deployment
    """

    # required defining data
    name: str
    flow_id: UUID
    entrypoint: str
    path: Optional[str] = None

    # workflow scheduling and parametrization
    parameters: Optional[Dict[str, Any]] = None
    parameter_openapi_schema: Optional[Dict[str, Any]] = None
    schedules: list[Schedule] = None
    paused: bool = False
    trigger: Trigger = None

    # concurrency limiting
    concurrency_limit: Optional[int] = None
    concurrency_options: Optional[
        ConcurrencyOptions(collision_strategy=Literal['ENQUEUE', 'CANCEL_NEW'])
    ] = None

    # metadata for bookkeeping
    version: Optional[str] = None
    description: Optional[str] = None
    tags: Optional[list] = None

    # worker-specific fields
    work_pool_name: Optional[str] = None
    work_queue_name: Optional[str] = None
    job_variables: Optional[Dict[str, Any]] = None
    pull_steps: Optional[Dict[str, Any]] = None
```

Prefect デプロイメントを作成するためのすべてのメソッドは、このスキーマを入力するためのインターフェイスです。

### 必要な定義データ

デプロイメントには、「名前」と基盤となる「フロー」への参照が必要です。

デプロイメント名はすべてのデプロイメント間で一意である必要はありませんが、特定のフローIDに対しては一意である必要があります。つまり、デプロイメントの一意の識別名である「{FLOW_NAME}/{DEPLOYMENT_NAME}」への参照が頻繁に使用されます。

例えば、Prefect CLI からデプロイメントの実行をトリガーするには、次のようにします:

```bash
prefect deployment run my-first-flow/my-first-deployment
```

または Python SDK から [`run_deployment`](https://reference.prefect.io/prefect/deployments/flow_runs/#prefect.deployments.flow_runs.run_deployment) を使用して実行することもできます。

{/* pmd-metadata: notest */}
```python
from prefect.deployments import run_deployment


run_deployment(
    name="my-first-flow/my-first-deployment",
    parameters={"my_param": "42"},
    job_variables={"env": {"MY_ENV_VAR": "staging"}},
    timeout=0, # don't wait for the run to finish
)
```

他の 2 つのフィールドは次のとおりです。

- **`path`**: パスはフローの実行時作業ディレクトリと考えてください。
たとえば、デプロイメントが Docker イメージ内に定義されたワークフローを参照する場合、`path` は、デプロイメントがトリガーされるたびにそのワークフローが実行される親ディレクトリへの絶対パスです。
この解釈は、リモートファイルシステムで定義されたフローの場合はより複雑です。
- **`entrypoint`**: デプロイメントのエントリポイントは、あるファイルシステム上に存在するフローとしてデコレートされた関数への相対参照です。常に `path` を基準として指定されます。
エントリポイントは、Python の標準的なオブジェクトへのパス構文を使用します (例: `path/to/file.py:function_name` または単に `path:object`)。

エントリポイントは、フロー ID と同じフローを参照する必要があります。

Prefect では、デプロイメントが _Python ファイル内_ で定義されたフローを参照する必要があります。
対話型 REPL またはノートブック内で定義されたフローは、現在、そのままではデプロイできません。
これらは有効なフローであり、実行されるたびに API によって監視され、UI で確認できますが、Prefect ではトリガーできません。

<Note>
**デプロイメントにはコード定義は含まれません**

デプロイメントメタデータは、環境内のさまざまな場所に存在する可能性のあるコードを参照します。
この分離により、フローコードはストレージと実行インフラストラクチャ内に留まります。

これがPrefectハイブリッドモデルの鍵となります。フローコードなどの独自の資産とPrefectバックエンド（[Prefect Cloud](/v3/manage/cloud/)を含む）の間には境界が存在します。
</Note>

### ワークフローのスケジューリングとパラメータ化

フローのデプロイメントを作成する主な目的の一つは、リモートからフローをスケジュールおよびトリガーすることです。
フローを異なる入力値を持つ関数として呼び出すことができるのと同様に、デプロイメントもパラメータを介して異なる値でトリガーまたはスケジュールできます。

これらのアクションに必要なメタデータを取得するためのフィールドは次のとおりです。

- **`schedules`**: [スケジュールオブジェクト](/v3/automate/add-schedules/)のリスト。
デプロイメントを作成するための便利なインターフェースのほとんどでは、ユーザーがこのオブジェクトを自分で作成する必要はありません。
例えば、[UIでデプロイメントスケジュールを更新する](/v3/automate/add-schedules/#creating-schedules-through-the-ui)場合、必要なのはcron文字列や間隔などの基本情報だけです。
- **`parameter_openapi_schema`**: フローのパラメータの型とデフォルトを定義する [OpenAPI 互換スキーマ](https://swagger.io/specification/)。
UI とバックエンドで、手動実行の作成オプションと型検証オプションを公開するために使用されます。
- **`parameters`**: このデプロイメントが各実行時に渡すフローパラメータのデフォルト値。
これらはトリガーまたはカスタム実行を手動で作成するときに上書きできます。
- **`enforce_parameter_schema`**: フロー実行に渡されるパラメータを、`parameter_openapi_schema` で定義されたスキーマに対して API が検証するかどうかを決定するブール型フラグ。

<Tip>
**スケジュールは非同期かつ分離されています**

スケジュールの一時停止、デプロイメントの更新、その他のアクションを実行すると、自動スケジュール実行がリセットされます。
</Tip>

### 同時実行の制限

Prefect はデプロイメントレベルでの同時実行の管理をサポートしており、デプロイメントの実行を一度にアクティブにできる回数を制限できます。この動作を有効にするために、デプロイメントには以下のフィールドがあります。

- **`concurrency_limit`**: デプロイメントで同時に実行できるフローの最大数を設定する整数。
- **`collision_strategy`**: 同時実行の制限に達した場合の実行の動作を設定します。
未設定の場合は `ENQUEUE` にフォールバックします。
- `ENQUEUE`: 新しい実行は `AwaitingConcurrencySlot` に遷移し、スロットが利用可能になると実行されます。
- `CANCEL_NEW`: スロットが利用可能になるまで、新しい実行はキャンセルされます。

<CodeGroup>

```sh prefect deploy
prefect deploy ... --concurrency-limit 3 --collision-strategy ENQUEUE
```

```python flow.deploy()
from prefect.client.schemas.objects import (
    ConcurrencyLimitConfig, 
    ConcurrencyLimitStrategy
)

my_flow.deploy(..., concurrency_limit=3)

my_flow.deploy(
    ...,
    concurrency_limit=ConcurrencyLimitConfig(
        limit=3, collision_strategy=ConcurrencyLimitStrategy.CANCEL_NEW
    ),
)
```

```python flow.serve()
from prefect.client.schemas.objects import (
    ConcurrencyLimitConfig, 
    ConcurrencyLimitStrategy
)

my_flow.serve(..., global_limit=3)

my_flow.serve(
    ...,
    global_limit=ConcurrencyLimitConfig(
        limit=3, collision_strategy=ConcurrencyLimitStrategy.CANCEL_NEW
    ),
)
```

</CodeGroup>

### 記録用メタデータ

バージョン、説明、タグの各フィールドに関する重要な情報:

- **`version`**: バージョンは常にクライアントによって設定され、任意の文字列を指定できます。
デプロイメントのこのフィールドは、ソフトウェア開発ライフサイクルと密接に連携させることをお勧めします。
例えば、`git` を使用してコード変更を管理する場合は、このフィールドにタグまたはコミットハッシュのいずれかを使用します。
バージョンの値を指定しない場合は、Prefect がハッシュを計算します。
- **`description`**: 使用目的やパラメータの説明などの参考資料を提供します。
Markdown が使用できます。フロー関数の docstring がデフォルト値です。
- **`tags`**: 多様なオブジェクトセットにまたがる関連する作業をグループ化します。
デプロイメントに設定されたタグは、そのデプロイメントのフロー実行に継承されます。タグによるフィルタリング、ビューのカスタマイズ、検索が可能です。

<Tip>
**すべてにバージョンがあります**

デプロイメントにはバージョンが付与されます。フローとタスクにも、それぞれのデコレータを通じてバージョンが設定されます。
これらのバージョンは、フローまたはタスクが実行されるたびにAPIに送信され、変更内容を監査できます。
</Tip>

### ワーカー固有のフィールド

[ワークプール](/v3/deploy/infrastructure-concepts/work-pools/) と [ワーカー](/v3/deploy/infrastructure-concepts/workers/) は、フロー実行ごとにインフラストラクチャを動的にプロビジョニングできる高度なデプロイメントパターンです。
ワークプールのジョブテンプレートインターフェースを使用すると、ユーザーはワークフローインフラストラクチャへの独自のインターフェースを作成および管理できます。
そのためには、ワーカーを使用するデプロイメントに以下のフィールドが必要です。

- **`work_pool_name`**: このデプロイメントが関連付けられているワークプールの名前。
ワークプールのタイプはインフラストラクチャのタイプを反映しているため、このフィールドは他のフィールドで使用できるオプションに影響します。
- **`work_queue_name`**: 優先度または同時実行性を管理するためにワークキューを使用している場合、このフィールドを使用して、デプロイメントをワークプール内の特定のキューに関連付けることができます。
- **`job_variables`**: このフィールドを使用すると、デプロイメント作成者は、このワークプールで公開されているインフラストラクチャオプションをカスタマイズできます。
このフィールドは、Docker イメージ名、Kubernetes のアノテーションと制限、環境変数などによく使用されます。
- **`pull_steps`**: フローコードまたは構成を取得し、ワークフロー実行用のランタイム環境を準備するステップの JSON 記述。

プルステップを使用すると、ユーザーはワークフローアーキテクチャを高度に分離できます。
例えば、プルステップの一般的な用途は、デプロイメントの実行ごとに GitHub などのリモートファイルシステムからコードを動的にプルすることです。
