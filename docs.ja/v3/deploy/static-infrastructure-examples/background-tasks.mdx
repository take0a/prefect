---
title: バックグラウンドタスクで動作するWebアプリケーションをデプロイする
description: Web アプリケーションから専用インフラストラクチャまで、負荷の高いタスクをバックグラウンドで実行する方法を学習します。
---

この例では、Prefect を使用した Web アプリケーションのコンテキストで、[バックグラウンドタスク](/v3/develop/deferred-tasks) を使用してタスクの送信、実行、監視、結果の保存を行う方法を示します。
FastAPI を使用してアプリケーションを構築し、クライアントに API エンドポイントを提供し、これらのエンドポイントが遅延させるバックグラウンドタスクをタスクワーカーで実行します。

<Tip>
完全な例のソース コードについては、[例のリポジトリ](https://github.com/PrefectHQ/examples/tree/main/apps/background-tasks) を参照してください。
</Tip>

このパターンは、データ処理、電子メールの送信、遅い可能性がある外部 API とのやり取りなど、標準の Web 要求応答サイクルには長すぎる操作を実行する必要がある場合に役立ちます。



## 概要

この例では、以下のものを構築します。

- バックグラウンドで実行するタスクを表す `@prefect.task` 定義
- 以下の API エンドポイントを提供する `fastapi` アプリケーション
  - タスクパラメータを `POST` リクエストで受け取り、`.delay()` を使用してタスクを Prefect に送信する
  - タスクの `task_run_id` を使用した `GET` リクエストでタスクのステータスをポーリングする
- Web アプリ、Prefect サーバー、タスクワーカーのマルチステージイメージを構築するための `Dockerfile`
- Web アプリ、Prefect サーバー、タスクワーカーのライフサイクルを管理するための `compose.yaml`

```bash
├── Dockerfile
├── README.md
├── compose.yaml
├── pyproject.toml
├── src
│   └── foo
│       ├── __init__.py
│       ├── _internal/*.py
│       ├── api.py
│       └── task.py
```

[examples リポジトリ](https://github.com/PrefectHQ/examples) をクローンするか、代わりに [`uv`](https://docs.astral.sh/uv/getting-started/installation/) を使用して独自の新しいプロジェクトをブートストラップすることもできます。

```bash
uv init --lib foo
uv add prefect marvin
```

このサンプル アプリケーションは、移植性と整理性を考慮して、`src/foo` ディレクトリを持つライブラリとして構造化されています。

<Note>
この例では、以下のものは必要ありません。
- Prefect Cloud
- Prefect Deployment の作成
- ワークプールの作成
</Note>

## 覚えておくと便利な点

- タスク定義（他のフローやタスクも含む）から任意の Python コードを呼び出すことができます。
- Prefect [Results](/v3/concepts/caching.html) を使用すると、タスク定義の `return` 値を結果ストレージ（ローカルディレクトリ、S3、GCS など）に保存/シリアル化できるため、[キャッシュ](/v3/develop/task-caching) と [べき等性](/v3/develop/transactions) が有効になります。


## バックグラウンドタスクの定義

バックグラウンド処理の中核は、`@prefect.task` で修飾された Python 関数です。
これにより、この関数は Prefect が管理できる作業単位（監視、キャッシュ、再試行など）としてマークされます。

{/* pmd-metadata: notest */}
```python src/foo/task.py
from typing import Any, TypeVar

import marvin

from prefect import task, Task
from prefect.cache_policies import INPUTS, TASK_SOURCE
from prefect.states import State
from prefect.task_worker import serve
from prefect.client.schemas.objects import TaskRun

T = TypeVar("T")


def _print_output(task: Task, task_run: TaskRun, state: State[T]):
    result = state.result()
    print(f"result type: {type(result)}")
    print(f"result: {result!r}")


@task(cache_policy=INPUTS + TASK_SOURCE, on_completion=[_print_output])
async def create_structured_output(data: Any, target: type[T], instructions: str) -> T:
    return await marvin.cast_async(
        data,
        target=target,
        instructions=instructions,
    )


def main():
    serve(create_structured_output)


if __name__ == "__main__":
    main()
```

主な詳細:

- `@task`: バックグラウンドで実行するタスクを定義するデコレータ。
- `cache_policy`: `INPUTS` と `TASK_SOURCE` に基づいたキャッシュ。
- `serve(create_structured_output)`: この関数は、新たに `delay()` されたタスク実行をサブスクライブするタスクワーカーを開始します。



## FastAPI アプリケーションの構築

FastAPI アプリケーションは、バックグラウンドタスクをトリガーし、そのステータスを確認するための API エンドポイントを提供します。

{/* pmd-metadata: notest */}
```python src/foo/api.py
import logging
from uuid import UUID

from fastapi import Depends, FastAPI, Response
from fastapi.responses import JSONResponse

from foo._internal import get_form_data, get_task_result, StructuredOutputRequest
from foo.task import create_structured_output

logger = logging.getLogger(__name__)

app = FastAPI()


@app.post("/tasks", status_code=202)
async def submit_task(
    form_data: StructuredOutputRequest = Depends(get_form_data),
) -> JSONResponse:
    """Submit a task to Prefect for background execution."""
    future = create_structured_output.delay(
        form_data.payload,
        target=form_data.target_type,
        instructions=form_data.instructions,
    )
    logger.info(f"Submitted task run: {future.task_run_id}")
    return {"task_run_id": str(future.task_run_id)}


@app.get("/tasks/{task_run_id}/status")
async def get_task_status_api(task_run_id: UUID) -> Response:
    """Checks the status of a submitted task run."""
    status, data = await get_task_result(task_run_id)

    response_data = {"task_run_id": str(task_run_id), "status": status}
    http_status_code = 200

    if status == "completed":
        response_data["result"] = data
    elif status == "error":
        response_data["message"] = data
        # Optionally set a different HTTP status for errors
    return JSONResponse(response_data, status_code=http_status_code)
```
<Accordion title="Prefectクライアントでタスクステータスを確認する">

`get_task_result` ヘルパー関数 (`src/foo/_internal/_prefect.py` 内) は、Prefect Python クライアントを使用して Prefect API と対話します:

```python src/foo/_internal/_prefect.py
from typing import Any, Literal, cast
from uuid import UUID


from prefect.client.orchestration import get_client
from prefect.client.schemas.objects import TaskRun
from prefect.logging import get_logger

logger = get_logger(__name__)

Status = Literal["completed", "pending", "error"]


def _any_task_run_result(task_run: TaskRun) -> Any:
    try:
        return cast(Any, task_run.state.result(_sync=True))  # type: ignore
    except Exception as e:
        logger.warning(f"Could not retrieve result for task run {task_run.id}: {e}")
        return None


async def get_task_result(task_run_id: UUID) -> tuple[Status, Any]:
    """Get task result or status.

    Returns:
        tuple: (status, data)
            status: "completed", "pending", or "error"
            data: the result if completed, error message if error, None if pending
    """
    try:
        async with get_client() as client:
            task_run = await client.read_task_run(task_run_id)
            if not task_run.state:
                return "pending", None

            if task_run.state.is_completed():
                try:
                    result = _any_task_run_result(task_run)
                    return "completed", result
                except Exception as e:
                    logger.warning(
                        f"Could not retrieve result for completed task run {task_run_id}: {e}"
                    )
                    return "completed", "<Could not retrieve result>"

            elif task_run.state.is_failed():
                try:
                    error_result = _any_task_run_result(task_run)
                    error_message = (
                        str(error_result)
                        if error_result
                        else "Task failed without specific error message."
                    )
                    return "error", error_message
                except Exception as e:
                    logger.warning(
                        f"Could not retrieve error result for failed task run {task_run_id}: {e}"
                    )
                    return "error", "<Could not retrieve error message>"

            else:
                return "pending", None

    except Exception as e:
        logger.error(f"Error checking task status for {task_run_id}: {e}")
        return "error", f"Failed to check task status: {str(e)}"
```

この関数は、API から `TaskRun` オブジェクトを取得し、その `state` をチェックして、`Completed`、`Failed`、あるいは `Pending`/`Running` 状態かどうかを判断します。
完了している場合は、`task_run.state.result()` を使用して結果を取得しようとします。
失敗した場合は、エラーメッセージを取得しようとします。


</Accordion>
## Docker イメージのビルド

マルチステージの `Dockerfile` を使用して、各サービス（Prefect サーバー、タスクワーカー、Web API）に最適化されたイメージを作成します。
このアプローチにより、イメージサイズを小さく抑え、ビルド依存関係とランタイム依存関係を分離できます。

```dockerfile Dockerfile
# Stage 1: Base image with Python and uv
FROM --platform=linux/amd64 ghcr.io/astral-sh/uv:python3.12-bookworm-slim as base

WORKDIR /app

ENV UV_SYSTEM_PYTHON=1
ENV PATH="/root/.local/bin:$PATH"

COPY pyproject.toml uv.lock* ./

# Note: We install all dependencies needed for all stages here.
# A more optimized approach might separate dependencies per stage.
RUN --mount=type=cache,target=/root/.cache/uv \
    uv pip install --system -r pyproject.toml

COPY src/ /app/src

FROM base as server

CMD ["prefect", "server", "start"]

# --- Task Worker Stage --- #
FROM base as task

# Command to start the task worker by running the task script
# This script should call `prefect.task_worker.serve(...)`
CMD ["python", "src/foo/task.py"]

# --- API Stage --- #
FROM base as api

# Command to start the FastAPI server using uvicorn
CMD ["uvicorn", "src.foo.api:app", "--host", "0.0.0.0", "--port", "8000"]

```

<Accordion title="Dockerfile の主な詳細">

- **ベースステージ (`base`)**: Python と `uv` をセットアップし、Docker キャッシュを利用するために `pyproject.toml` からすべての依存関係をベースレイヤーにインストールし、ソースコードをコピーします。
- **サーバーステージ (`server`)**: `base` ステージをビルドします。Prefect サーバーを起動するためのデフォルトコマンド (`CMD`) を設定します。
- **タスクワーカーステージ (`task`)**: `base` ステージをビルドします。`CMD` を設定して、タスクの `serve()` 呼び出しを含む `src/foo/task.py` スクリプトを実行します。
- **API ステージ (`api`)**: `base` ステージをビルドします。
`uvicorn` を使用して FastAPI アプリケーションを起動するための `CMD` を設定します。

次に、`compose.yaml` ファイルは `target` ビルド引数を使用して、各サービス コンテナに使用する最終ステージ (`server`、`task`、`api`) を指定します。

</Accordion>

## アプリケーションサービスの宣言

`compose.yaml` を使用して、マルチコンテナアプリケーションを定義および実行し、FastAPI ウェブサーバー、Prefect API サーバー、データベース、タスクワーカーのライフサイクルを管理します。

```yaml compose.yaml
services:

  prefect-server:
    build:
      context: .
      target: server
    ports:
      - "4200:4200"
    volumes:
      - prefect-data:/root/.prefect # Persist Prefect DB
    environment:
      # Allow connections from other containers
      PREFECT_SERVER_API_HOST: 0.0.0.0
  # Task Worker
  task:
    build:
      context: .
      target:
    deploy:
      replicas: 1 # task workers are safely horizontally scalable (think redis stream consumer groups)
    volumes:
      # Mount storage for results
      - ./task-storage:/task-storage
    depends_on:
      prefect-server:
        condition: service_started
    environment:
      PREFECT_API_URL: http://prefect-server:4200/api
      PREFECT_LOCAL_STORAGE_PATH: /task-storage
      PREFECT_LOGGING_LOG_PRINTS: "true"
      PREFECT_RESULTS_PERSIST_BY_DEFAULT: "true"
      MARVIN_ENABLE_DEFAULT_PRINT_HANDLER: "false"
      OPENAI_API_KEY: ${OPENAI_API_KEY}

    develop:
      # Optionally watch for code changes for development
      watch:
        - action: sync
          path: .
          target: /app
          ignore:
            - .venv/
            - task-storage/
        - action: rebuild
          path: uv.lock

  api:
    build:
      context: .
      target: api
    volumes:
      # Mount storage for results
      - ./task-storage:/task-storage
    ports:
      - "8000:8000"
    depends_on:
      task:
        condition: service_started
      prefect-server:
        condition: service_started
    environment:
      PREFECT_API_URL: http://prefect-server:4200/api
      PREFECT_LOCAL_STORAGE_PATH: /task-storage
    develop:
      # Optionally watch for code changes for development
      watch:
        - action: sync
          path: .
          target: /app
          ignore:
            - .venv/
            - task-storage/
        - action: rebuild
          path: uv.lock

volumes:
  # Named volumes for data persistence
  prefect-data: {}
  task-storage: {}
```

本番環境でのユースケースでは、おそらく以下の手順が必要になるでしょう。
- サービスごとに `Dockerfile` を作成する
- `postgres` サービスを追加し、[Prefect データベースとして設定](/v3/manage/server/index#quickstart%3A-configure-a-postgresql-database-with-docker)する
- `develop` セクションのホットリロード設定を削除する

<Accordion title="主要なサービス構成">

- **`prefect-server`**: Prefect API サーバーと UI を実行します。
    - `build`: `server` ステージをターゲットとするマルチステージ `Dockerfile` (ここでは示されていませんが、サンプルリポジトリには存在します) を使用します。
    - `ports`: ポート `4200` で Prefect API/UI を公開します。
    - `volumes`: 名前付きボリューム `prefect-data` を使用して、コンテナの再起動後も Prefect SQLite データベース (`/root/.prefect/prefect.db`) を保持します。
    - `PREFECT_SERVER_API_HOST=0.0.0.0`: API サーバーが Docker ネットワーク内のすべてのインターフェースを listen するようにし、`task` サービスと `api` サービスが接続できるようにします。

- **`task`**: Prefect タスクワーカープロセスを実行します（`serve` を呼び出す `python src/foo/task.py` を実行します）。
    - `build`: `Dockerfile` の `task` ステージを使用します。
    - `depends_on`: このサービスが接続を試みる前に、`prefect-server` サービスが起動されていることを確認します。
    - `PREFECT_API_URL`: ワーカーに、送信されたタスク実行をポーリングするための Prefect API の場所を指示する重要な設定です。
    - `PREFECT_LOCAL_STORAGE_PATH=/task-storage`: ワーカーがタスク実行結果をコンテナ内の `/task-storage` ディレクトリに保存するように設定します。このパスは、`volumes: - ./task-storage:/task-storage` （ホストパスバインディングのない名前付きボリュームを使用している場合は、単に `task-storage:`）を介して、`task-storage` 名前付きボリュームを使用してホストにマウントされます。
    - `PREFECT_RESULTS_PERSIST_BY_DEFAULT=true`：Prefect タスクに、設定されたストレージ（この場合は `PREFECT_LOCAL_STORAGE_PATH` で定義）を使用して結果を自動的に保存するように指示します。
    - `PREFECT_LOGGING_LOG_PRINTS=true`：タスク内の `print()` ステートメントの出力をキャプチャするように Prefect ロガーを設定します。
    - `OPENAI_API_KEY=${OPENAI_API_KEY}`：タスクコードに必要なシークレットを、ホスト環境（Docker Compose によって読み込まれた `.env` ファイル経由）からコンテナの環境に渡します。

- **`api`**: FastAPI Webアプリケーションを実行します。
    - `build`: `Dockerfile`の`api`ステージを使用します。
    - `depends_on`: `prefect-server`（タスクの送信とステータスの確認に必要）と、オプションで`task`ワーカーを待機します。
    - `PREFECT_API_URL`: FastAPIアプリケーションに、`.delay()`呼び出しとステータスチェックリクエストの送信先を指定します。
    - `PREFECT_LOCAL_STORAGE_PATH`: API自体が結果ファイルを直接読み取る必要がある場合に必要になる場合があります（ただし、通常は`task_run.state.result()`を介して結果を取得することが推奨されます）。

- **`volumes`**: コンテナによって生成されたデータを永続化するために、名前付きボリューム (`prefect-data`、`task-storage`) を定義します。

</Accordion>

## この例の実行

リポジトリをクローンするか、前述のように `uv init` を使用することでコードを取得し、プロジェクトディレクトリにいることを前提としています。

1. **前提条件:** `docker compose` をサポートする Docker Desktop（または同等のツール）が実行中であることを確認してください。

2. **サービスのビルドと実行:**
この例のタスクでは [marvin](https://github.com/PrefectHQ/marvin) を使用します。これは（デフォルトで）OpenAI API キーを必要とします。サービス起動時に環境変数としてキーを指定してください:

    ```bash
    OPENAI_API_KEY=<your-openai-api-key> docker compose up --build --watch
    ```

    このコマンドは以下の処理を行います:
    * `--build`: コンテナイメージが存在しない場合、またはDockerfile/コンテキストが変更されている場合にビルドします。
    * `--watch`: プロジェクトのソースコードの変更を監視し、サービスを自動的に同期/再構築します（開発時に便利です）。
    * コンテナをバックグラウンドで実行するには、`--detach` または `-d` を追加します。

3. **アクセスサービス:**
    - 既存のサンプルをクローンした場合は、[http://localhost:8000](http://localhost:8000) にある基本的な [htmx](https://htmx.org/) UI をご確認ください。
    - FastAPI ドキュメント: [http://localhost:8000/docs](http://localhost:8000/docs)
    - Prefect UI (タスク実行の監視用): [http://localhost:4200](http://localhost:4200)

### 掃除

```bash
docker compose down

# also remove the named volumes
docker compose down -v
```

## 次のステップ

この例は、Prefect が管理するバックグラウンドタスクを任意の Python Web アプリケーションに統合するための繰り返し可能なパターンを提供します。以下のことが可能です。

- その他の例については、[バックグラウンドタスクのサンプルリポジトリ](https://github.com/PrefectHQ/prefect-background-task-examples) を参照してください。
- `src/**/*.py` を調整して、特定の Web アプリとバックグラウンドタスクを定義し、送信します。
- Prefect の設定（`compose.yaml` 内の環境変数）をさらに設定します（例：異なる結果の保存方法やログレベルを使用する）。
- マネージドコンテナサービスを使用して、これらのサービスをクラウドインフラストラクチャにデプロイします。