---
title: サーバーレス インフラストラクチャに回復力のあるパイプラインを展開する
description: パイプラインの障害を処理し、サーバーレス インフラストラクチャにデプロイする方法を学びます。
---
import { Arcade } from '/snippets/arcade.mdx'

このチュートリアルは、[S3 と MotherDuck のチュートリアル](/docs/v3/tutorials/s3-motherduck)で作成されたメジャーリーグベースボール (MLB) フローをベースに構築されています。
ここでは、フローに障害処理とデータ品質チェックを追加し、Prefect Cloud の [マネージド実行ワークプール](/v3/deploy/infrastructure-examples/managed#run-flows-on-prefect-managed-infrastructure) を使用してデプロイする方法について説明します。

各セクションの作業を進める際には、この YouTube 動画をご覧ください。

<iframe 
width="560" 
height="315" 
src="https://www.youtube.com/embed/TicCCxDncsM?si=q7TStZ_9ltEWA692" 
title="YouTube video player" 
frameborder="0" 
allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" 
referrerpolicy="strict-origin-when-cross-origin" 
allowfullscreen>
</iframe>

## 前提条件

このチュートリアルのパイプラインは、データの保存に S3 と MotherDuck を使用します。
MotherDuck は、DuckDB をベースに構築された、サーバーレスでクラウドに最適化された分析プラットフォームです。
パイプラインを実行するには、以下のものが必要です。

* 無料の [Prefect Cloud アカウント](https://app.prefect.cloud/)
* 無料の [MotherDuck アカウント](https://motherduck.com/)。以下のものが必要です。
    * MotherDuck トークン
    * MotherDuck トークンを含む Prefect Cloud の Secret ブロック
* [AWS アカウント](https://aws.amazon.com/free/)。以下のものが必要です。
    * 「AmazonS3FullAccess」権限を持つ IAM ユーザー
    * S3 バケット
    * Prefect Cloud の S3 ブロック

AWS および MotherDuck のリソースが不足している場合は、[S3 と MotherDuck のチュートリアル](/v3/tutorials/s3-motherduck) の手順に従って作成できます。

### 環境設定

完全なコード例は、[dev-day-zoom-out リポジトリ](https://github.com/PrefectHQ/dev-day-zoom-out) にあります。

まず、以下のコマンドを実行して `dev-day-zoom-out` リポジトリをクローンします:

```bash
git clone https://github.com/PrefectHQ/dev-day-zoom-out.git
```

リポジトリのルートにある README.md ファイルに従って環境を設定してください。
完了したら、このチュートリアルのすべてのコードが配置されているディレクトリに移動します。

```bash
cd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/
```

## 失敗処理

Prefect は、パイプラインの失敗を処理するためのさまざまな方法を提供しています。
このセクションでは、いくつかの異なる再試行戦略を検討します。
これらの再試行モードの動作を確認するには、各コードスニペットをコピーし、MLB パイプラインの元の `get_recent_games` タスクを置き換えてください。

次のコマンドを実行して、変更するパイプラインを含むディレクトリに移動します。

```bash
cd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/1_starting_flow
```

次のコードスニペットは、`mlb_flow.py` ファイルにある `get_recent_games` タスクに異なる再試行を適用する方法を示しています。
タスク自体には、ランダムな API 障害をシミュレートするためにいくつかの変更が加えられています。

### シンプルな再試行を実装する

この例では、`@task` デコレータを使用してシンプルな再試行戦略を適用する方法を示します。
既存の `get_recent_games` タスクを以下のコードに置き換えます。

{/* pmd-metadata: notest */}
```python

# Get recent games, and retry 10 times if the API fails.
@task(retries=10)
def get_recent_games(team_name, start_date, end_date):
     # Simulate random API failure (70% chance).
    if random.random() < 0.7:
        time.sleep(2)  # Add a delay to see the retries in action.
        raise Exception("Simulated API failure: MLB Stats API is temporarily unavailable")
    
    # Get all games for the provided team and date range.
    team = statsapi.lookup_team(team_name)
    schedule = statsapi.schedule(team=team[0]["id"], start_date=start_date, end_date=end_date)
    for game in schedule:
        print(game['game_id'])
    return [game['game_id'] for game in schedule]
```


### 遅延再試行を実装する

Prefect の遅延再試行は、タスクまたはフローの実行が失敗した場合に、指定された遅延時間後に自動的に再試行するメカニズムです。
この機能は、一時的なエラーや、レート制限やネットワークの問題など、外部システムの一時的な問題を処理する場合に特に便利です。
この再試行戦略を実装するには、`get_recent_games` タスクの `@task` デコレータに `retry_delay_seconds` ユーティリティを追加します。

{/* pmd-metadata: notest */}
```python

# The retry_delay_seconds option accepts a list of integers for customized retry behavior.
# This task will retry 10 times with a delay of 1 second each time.
@task(retries=10, retry_delay_seconds=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
def get_recent_games(team_name, start_date, end_date):
    # Simulate random API failure (70% chance).
    if random.random() < 0.7:
        raise Exception("Simulated API failure: MLB Stats API is temporarily unavailable")
    
    # If no failure, proceed with actual API call.
    team = statsapi.lookup_team(team_name)
    schedule = statsapi.schedule(team=team[0]["id"], start_date=start_date, end_date=end_date)
    for game in schedule:
        print(game['game_id'])
    return [game['game_id'] for game in schedule]
```


### 指数関数的な再試行を実装する

指数関数的なバックオフとは、再試行間の遅延が指数関数的に増加する再試行戦略です。
これは、後続の再試行の待機時間が前回よりも長くなることを意味します。
Prefect では、`get_recent_games` タスクの `@task` デコレータに `exponential_backoff` ユーティリティを追加することでこれを実装できます。

{/* pmd-metadata: notest */}
```python
# The exponential_backoff utility will automatically generate a list of retry delays that correspond to an exponential backoff retry strategy.
# This task will retry 10 times with a delay of 2, 4, 8, and 16 seconds.
@task(retries=4, retry_delay_seconds=exponential_backoff(backoff_factor=2))
def get_recent_games(team_name, start_date, end_date):
    # Simulate random API failure (70% chance).
    if random.random() < 0.1:
        raise Exception("Simulated API failure: MLB Stats API is temporarily unavailable")
    
    # Get all games for the provided team and date range.
    team = statsapi.lookup_team(team_name)
    schedule = statsapi.schedule(team=team[0]["id"], start_date=start_date, end_date=end_date)
    for game in schedule:
        print(game['game_id'])
    return [game['game_id'] for game in schedule]
```


### 再試行ハンドラを実装する

Prefect の再試行ハンドラは、特定の条件に基づいてタスクを再試行するかどうかを決定するカスタム関数です。
これは、特定の例外が発生した場合にのみ再試行するなど、より複雑な再試行ロジックに役立ちます。
再試行ハンドラを実装するには、タスクを再試行するかどうかを決定するために Prefect が使用する別の関数を定義する必要があります。
この関数は、`task`、`task_run`、`state` の 3 つの引数を取ります。
タスクを再試行するかどうかを示すブール値を返します。
`mlb_flow.py` ファイルに次のコードスニペットを追加します。

{/* pmd-metadata: notest */}
```python

# Custom retry handler.
def retry_handler(task, task_run, state) -> bool:
    """Custom retry handler that specifies when to retry a task"""
    try:
        # Attempt to get the result of the task.
        state.result()
    except Exception as e:
        # If Exception is a TimeoutError, retry.
        if isinstance(e, TimeoutError):
            return True
        # For any other exception, do not retry.
        return False

```


ハンドラーを定義したら、`retry_condition_fn` パラメータを使用して `@task` デコレータに追加できます。
既存の `get_recent_games` タスクを以下のものに置き換えます。

{/* pmd-metadata: notest */}
```python
# The retry_condition_fn parameter enables us to specify a custom retry condition function
@task(retries=10, retry_condition_fn=retry_handler)
def get_recent_games(team_name, start_date, end_date):
    # Generate random number.
    failure_chance = random.random()
    
    # Simulate different types of failures.
    if failure_chance < 0.3:
        time.sleep(2)  # Allow us to see the retries in action.
        raise Exception("Simulated API failure: MLB Stats API is temporarily unavailable")
    elif failure_chance >= 0.4:
        time.sleep(2)  # Allow us to see the retries in action.
        raise TimeoutError("Simulated timeout: Request took too long") # Simulate empty response.
    
    # If no failure, proceed with actual API call.
    team = statsapi.lookup_team(team_name)
    schedule = statsapi.schedule(team=team[0]["id"], start_date=start_date, end_date=end_date)
    for game in schedule:
        print(game['game_id'])
    return [game['game_id'] for game in schedule]
```


すべての再試行オプションの完全な例を確認するには、次のコマンドを実行します:

```bash
cd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/2_retries
```

## データ品質チェックの追加

Prefect の [トランザクション インターフェース](/v3/develop/transactions#write-transactions) は、ワークフローの回復力と冪等性を高める強力な機能です。
これは、実行時パフォーマンスの向上とタスクの自律実行に貢献します。
また、トランザクションを使用すると、on-commit フックと on-rollback フックを利用して、副作用や障害に対処することもできます。
このセクションでは、トランザクション インターフェースを使用して、生のゲームデータのデータ品質チェックを実装します。

以下のコマンドを実行して、変更するパイプラインを含むディレクトリに移動します。

```bash
cd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/1_starting_flow
```

まず、`prefect.transactions` モジュールから `transaction` ユーティリティをインポートする必要があります。

{/* pmd-metadata: notest */}
<Expandable title="Necessary Imports">
```python
# Add this import to your script.
from prefect.transactions import transaction
```
</Expandable>

以下のコードスニペットは、スクリプトの残りのタスクが定義されている部分に追加できます。
データ品質チェックが失敗した場合にファイルを削除するように設計された `on_rollback` フックがあります。
ファイル内に5件未満のエントリが見つかった場合、データ品質チェックは失敗し、ロールバックがトリガーされます。

<Expandable title="Data Quality Check and Rollback">
{/* pmd-metadata: notest */}
```python
# Paste this code snippet where the rest of the tasks are defined.

# An on_rollback function is defined to delete the file if the data quality check fails.
@save_raw_data_to_file.on_rollback
def del_file(txn):
    "Deletes file."
    os.unlink(txn.get("filepath"))
    
# A quality_test task is defined to check if there is sufficient game data in the file.
@task
def quality_test(file_path):
    "Checks contents of file."
    with open(file_path, "r") as f:
        data = json.load(f)
        
    if len(data) < 5:
        raise ValueError(f"Not enough data! There are only {len(data)} games in the file.")
```
</Expandable>

フロー関数に、生のゲームデータを含むファイルに対してデータ品質チェックを実行するトランザクションブロックを追加します。
既存の `mlb_flow` 関数を以下のものに置き換えます。

<Expandable title="Flow with Transaction Block">
{/* pmd-metadata: notest */}
```python
@flow
def mlb_flow_rollback(team_name, start_date, end_date):
    # Get recent games.
    game_ids = get_recent_games(team_name, start_date, end_date)
    
    # Fetch boxscore for each game.
    game_data = [fetch_single_game_boxscore(game_id, start_date, end_date, team_name) for game_id in game_ids]
    
    # Define file path for raw data.
    today = datetime.now().strftime("%Y-%m-%d") #YYYY-MM-DD.
    flow_run_name = runtime.flow_run.name
    raw_file_path = f"./raw_data/{today}-{team_name}-{flow_run_name}-boxscore.json"
    
    # Create transaction which will be used to rollback if the data quality test fails.
    with transaction() as txn:
        txn.set("filepath", raw_file_path)
        # Save raw data to a file.
        save_raw_data_to_file(game_data, raw_file_path)
        time.sleep(10)  # Add a delay to give you a chance to see the file.
        quality_test(raw_file_path)
        # Upload raw data to s3.
        s3_file_path = upload_raw_data_to_s3(raw_file_path)
    
    
    # Download raw data from s3.
    raw_data = download_raw_data_from_s3(s3_file_path)
    
    # Clean the time value. 
    clean_data = clean_time_value(raw_data)
    
    # Analyze the results.  
    results = analyze_games(clean_data)
    
    # Save the results to a parquet file.
    parquet_file_path = f"./boxscore_parquet/{today}-{team_name}-{flow_run_name}-game-analysis.parquet"
    save_analysis_to_file(results, parquet_file_path)
    
    # Load the results to duckdb.
    load_parquet_to_duckdb(parquet_file_path, team_name)
    
    # Save the results to a Prefect artifact.
    game_analysis_artifact(results, raw_data)
    
    
if __name__ == "__main__":
    # Uncomment this line to kick off a successful flow run.
    #mlb_flow_rollback("marlins", '06/01/2024', '06/30/2024')

    # Uncomment this line to kick off a flow run that will fail the data quality check.
    #mlb_flow_rollback("marlins", '06/01/2024', '06/02/2024')
```
</Expandable>

on-rollback フックの動作を確認するには、品質チェックに必要なデータよりも少ないゲームデータを生成する日付範囲を使用してフローを実行します。
ロールバック実行前に発生する 10 秒間のバッファにより、フックによって削除される生データファイルが raw_data フォルダに生成され、そこから出ていく様子を確認できます。

このセクションの完全なコードを確認するには、次のコマンドを実行してディレクトリに移動してください:

```bash
cd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/3_rollbacks
```

## マネージド実行によるデプロイ

このセクションでは、MLBフローをサーバーレスインフラストラクチャにデプロイします。
これにより、このフローをスケジュールに従って実行する場合、ラップトップを24時間365日オンにしておく必要がなくなります。
具体的には、フローをPrefectのマネージド実行ワークプールにデプロイします。
マネージド実行を使用すると、リモートで作業を実行するために独自のクラウドプロバイダーインフラストラクチャを構成することなく、Prefect Cloudのインフラストラクチャ上でフローを実行できます。

### マネージドワークプールを作成する

ターミナルからPrefect Cloudに認証されている場合は、次のコマンドを実行して新しいワークプールを作成できます。

```bash
prefect work-pool create managed-pool --type prefect:managed
```

<Tip>
Prefect Cloud UI で **Work Pools** ページに移動すると、新しいワーク プールを作成できます。
</Tip>

### デプロイメントスクリプトを実行します

このコマンドを使用して、デプロイメントスクリプトが格納されているディレクトリに移動します。

```bash
cd dev-day-zoom-out/track_1_build_workflows/session_2_resilent_workflows/4_deploy_and_schedule
```

次のコード スニペットは、`from_source()` メソッドと `deploy()` メソッドを使用する `mlb_flow_deploy.py` スクリプトの内容を示しています。

{/* pmd-metadata: notest */}
```python
from prefect import flow
from pathlib import Path

# This helper function reads the requirements.txt file.
def read_requirements(file_path="requirements.txt"):
    """Read and parse requirements.txt file"""
    requirements = Path(file_path).read_text().splitlines()
    # Filter out empty lines and comments.
    return [req.strip() for req in requirements if req.strip() and not req.startswith('#')]

if __name__ == "__main__":
    flow.from_source(
        source="https://github.com/PrefectHQ/dev-day-zoom-out.git",
        entrypoint="track_1_build_workflows/session_2_resilent_workflows/4_deploy_and_schedule/mlb_flow_managed.py:mlb_flow",
    ).deploy(
        name="mlb-managed-flow",
        work_pool_name="managed-pool",
        parameters={"team_name": "phillies", "start_date": "06/01/2024", "end_date": "06/30/2024"},
        job_variables={"pip_packages": read_requirements()}
    )


```

`from_source()` メソッドは、デプロイメントを作成する際にフローコードの場所を指定します。
これは、Docker イメージにフローコードを組み込むのではなく、実行時にリモートストレージからフローコードを取得する場合に特に便利です。
このメソッドは 2 つの引数を取ります。Git リポジトリまたはストレージオブジェクトへの URL、フローと関数名を含むファイルへのパス（コロンで区切る）です。

`.deploy()` メソッドを使用すると、Python コードでプログラム的にデプロイメントを定義できます。
このメソッドは、デプロイメントの名前、作業を送信するワークプール、フローに渡すパラメータのディクショナリを受け取ります。
また、フローの実行環境にインストールするパッケージのリストを受け入れる `job_variables` パラメータもあります。

パッケージリストは `read_requirements` ヘルパー関数によって生成されます。
この関数は、デプロイメントスクリプトを含むディレクトリ内の `requirements.txt` ファイルを読み取り、フローの実行環境にインストールするパッケージのリストを返します。

デプロイメントスクリプトの動作を確認するには、次のコマンドを使用して実行します。

```bash
python mlb_flow_deploy.py
```

Prefect Cloud に新しいデプロイメントが作成されました。
Prefect Cloud UI の **Deployments** ページに移動すると、新しいデプロイメントが表示されます。
新しいフロー実行を開始するには、**Quick run** ボタンをクリックします。

### スケジュールを追加

お疲れ様でした！MLBフローをサーバーレスインフラストラクチャにデプロイしました。
デプロイにスケジュールを追加して、定期的に実行できるようになりました。

#### Python SDK を使用したスケジュール設定

[Cron スケジュール](/v3/automate/add-schedules#cron) は、特定の時間、曜日、または月にワークフローを実行するためによく使用されます。
次の例は、フローが毎日午前 0 時に実行されるように、デプロイメントに cron スケジュールを追加する方法を示しています。
mlb_flow_deploy.py ファイルに変更を加えて再度実行し、実際に試してみてください。

{/* pmd-metadata: notest */}
```python
from prefect import flow
from pathlib import Path

# This helper function reads the requirements.txt file.
def read_requirements(file_path="requirements.txt"):
    """Read and parse requirements.txt file"""
    requirements = Path(file_path).read_text().splitlines()
    # Filter out empty lines and comments.
    return [req.strip() for req in requirements if req.strip() and not req.startswith('#')]

if __name__ == "__main__":
    flow.from_source(
        source="https://github.com/PrefectHQ/dev-day-zoom-out.git",
        entrypoint="track_1_build_workflows/session_2_resilent_workflows/4_deploy_and_schedule/mlb_flow_managed.py:mlb_flow",
    ).deploy(
        name="mlb-managed-flow",
        work_pool_name="managed-pool",
        parameters={"team_name": "phillies", "start_date": "06/01/2024", "end_date": "06/30/2024"},
        job_variables={"pip_packages": read_requirements()},
        # This schedule will run the flow every day at 12:00 AM.
        cron="0 0 * * *"
    )
```


更新されたスクリプトを実行すると、Prefect Cloud UI でデプロイメントに新しいスケジュールが追加されていることを確認できます。
Prefect は `interval` および `rrule` スケジュールタイプもサポートしています。

[間隔スケジュール](/v3/automate/add-schedules#interval) は、特定の間隔でフローを実行する場合に便利です。
例えば、10分ごとにフローを実行できます。

{/* pmd-metadata: notest */}
```python
# Run every 10 minutes.
interval=timedelta(minutes=10)
```

より複雑な繰り返しパターンを実現するために、Prefect は [RRule スケジュール](/v3/automate/add-schedules#rrule) をサポートしています。
例えば、毎月月曜日、水曜日、金曜日の午後 4 時にワークフローを実行するなどです。

{/* pmd-metadata: notest */}
```python
# Run Monday, Tuesday, Wednesday, Thursday, Friday at 4:00 PM UTC.
rrule="FREQ=WEEKLY;BYDAY=MO,TU,WE,TH,FR;BYHOUR=16;BYMINUTE=0"
```

#### Prefect Cloud UI でスケジュールを追加する

Prefect Cloud UI を使用してデプロイメントにスケジュールを追加する場合は、デプロイメントに移動し、**+ Schedule** をクリックします。

<Arcade src={"https://demo.arcade.software/XYwssAx9RdPJ1EcPcsCd"} title={"Mastering Deployment Scheduling for Optimal Performance"} />

## 次のステップ

このチュートリアルでは、以下の方法を学習しました。
* パイプラインの失敗と再試行の処理
* データ品質チェックとロールバックの実装
* サーバーレス インフラストラクチャへのフローのデプロイ
* デプロイメントへのスケジュールの追加

Prefect のさまざまな [ワークプール タイプ](/v3/deploy/infrastructure-concepts/work-pools) を確認し、Docker、Kubernetes、またはお好みのクラウドプロバイダーにフローをデプロイすることで、Prefect をさらに活用できます。
さらにワークフローを構築したい場合は、[機械学習モデルのトレーニング](/v3/tutorials/ml) で機械学習パイプラインの構築方法を学習してください。
